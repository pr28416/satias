@inproceedings{Manmatha00,
  author    = {Manmatha, R. and Rath, Tushar M. and Feng, Fangfang},
  title     = {Searching Text in Images},
  year      = {2000},
  booktitle = {CIIR Technical Report},
  publisher = {University of Massachusetts Amherst},
  url       = {https://ciir-publications.cs.umass.edu/getpdf.php?id=317}
}

@inproceedings{Mai17,
  author    = {Mai, Long and Zhang, Hanqing and Feng, Zuxuan},
  title     = {Spatial-Semantic Image Search},
  year      = {2017},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages     = {5589--5598},
  url       = {https://openaccess.thecvf.com/content_cvpr_2017/papers/Mai_Spatial-Semantic_Image_Search_CVPR_2017_paper.pdf}
}

@inproceedings{Karpathy14,
  author    = {Karpathy, Andrej and Fei-Fei, Li},
  title     = {Deep Fragment Embeddings for Bidirectional Image Sentence Mapping},
  year      = {2014},
  booktitle = {Advances in Neural Information Processing Systems},
  volume    = {27},
  publisher = {Curran Associates, Inc.},
  url       = {https://arxiv.org/pdf/1406.5679}
}

@article{Faghri17,
  author  = {Faghri, Fartash and Fleet, David J. and Kiros, Jamie Ryan and Fidler, Sanja},
  title   = {VSE++: Improving Visual-Semantic Embeddings with Hard Negatives},
  year    = {2017},
  journal = {arXiv preprint arXiv:1707.05612},
  url     = {https://arxiv.org/pdf/1707.05612}
}

@article{Cao23,
  author  = {Cao, Moning and Bai, Yi and Wang, Jingjing and Cao, Zhengchen and Nie, Liqiang and Zhang, Min},
  title   = {Efficient Image-Text Retrieval via Keyword-Guided Pre-Screening},
  year    = {2023},
  journal = {arXiv preprint arXiv:2303.07740},
  url     = {https://arxiv.org/pdf/2303.07740}
}

@inproceedings{Chen23,
  author    = {Chen, Zinan and Zhu, Yunming and Zhang, Wenxian and Joty, Shafiq R. and Bing, Lidong},
  title     = {STAIR: Learning Sparse Text and Image Representation in Grounded Tokens},
  year      = {2023},
  booktitle = {ICLR 2023 Workshop},
  url       = {https://openreview.net/forum?id=HXUdnYIe8r}
}

@article{Bai24,
  author  = {Bai, Yi and Yu, Zhihe and Xu, Xin and Yang, Xi and Wang, Xinbo and Qin, Bing},
  title   = {Efficient Text-Image Sparse Retrieval via Bernoulli Random Variables Controlled Query Expansion},
  year    = {2024},
  journal = {arXiv preprint arXiv:2402.17535},
  url     = {https://arxiv.org/pdf/2402.17535}
}

@inproceedings{Huang24,
  author    = {Huang, Zhengyuan and Lv, Feng and Bai, Wenhui and Wang, Xiaojun and Liu, Jingzhou and Yang, Haoran and others},
  title     = {Grounding Multimodal Large Language Models to the World},
  year      = {2024},
  booktitle = {International Conference on Learning Representations (ICLR)},
  url       = {https://openreview.net/pdf/0ea36b222b82ac76c018c9aa7a47f9f978c705b2.pdf}
}

@inproceedings{Yin24,
  author    = {Yin, Zhenfei and Chen, Conghui and Savva, Manolis and Sung, Fangbo},
  title     = {Groma: Grounded Multimodal Large Language Model with Localized Visual Tokenization},
  year      = {2024},
  booktitle = {European Conference on Computer Vision (ECCV)}
}

@inproceedings{Changpinyo21,
  author    = {Changpinyo, Soravit and Sharma, Piyush and Ding, Nan and Soricut, Radu},
  title     = {Telling the What While Pointing to the Where: Multimodal Queries for Image Retrieval},
  year      = {2021},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages     = {1528--1538},
  url       = {https://openaccess.thecvf.com/content/ICCV2021/papers/Changpinyo_Telling_the_What_While_Pointing_to_the_Where_Multimodal_Queries_ICCV_2021_paper.pdf}
}

@article{Nguyen25,
  author  = {Nguyen, Hoang D. and Bull, Andrew N. and Nair, Vinod},
  title   = {Where is this coming from? Making groundedness count in the evaluation of Document VQA models},
  year    = {2025},
  journal = {arXiv preprint arXiv:2503.19120},
  url     = {https://arxiv.org/html/2503.19120v1}
} 